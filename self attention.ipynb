{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "L, d_k, d_v = 4, 8, 8\n",
    "q = np.random.randn(L, d_k)\n",
    "k = np.random.randn(L, d_k)\n",
    "v = np.random.randn(L, d_v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.1338676  -1.31787852 -0.81580438  0.10849314 -1.86438204 -2.29125958\n",
      "   0.20237417  1.22667764]\n",
      " [-0.12566382 -0.85288647  0.31339589 -0.76331267 -0.05254395  0.17963946\n",
      "  -1.25004825  0.33494957]\n",
      " [ 0.05911044  0.07593472  0.63216622 -0.223841    0.93323609 -1.2360208\n",
      "  -2.64525418  0.48687464]\n",
      " [ 0.59815955 -0.27984435 -0.91039285 -0.19008769  0.63416699  1.99340053\n",
      "   0.90365102 -0.10097996]]\n",
      "K\n",
      " [[ 0.77327056  0.0451663   0.6615367  -0.26743661  0.49088125  0.54616399\n",
      "   0.63656231  0.88535059]\n",
      " [ 0.28640497  0.38361717  2.421019   -0.04920616  0.73570624  1.25312975\n",
      "  -2.25649879 -1.55276228]\n",
      " [ 0.12004555  0.77612413 -0.90071078 -0.11322133  1.60818544 -0.44628416\n",
      "   0.49328192  1.12050032]\n",
      " [-1.48390683  0.30182879 -0.26292456 -0.30120886  0.46111164 -1.08276636\n",
      "   0.76887877  1.16688117]]\n",
      "V\n",
      " [[ 0.47000748  1.67941975 -0.58124951  0.24262047 -0.96695464 -0.63551672\n",
      "   1.1676836   1.84772634]\n",
      " [ 0.42559906 -0.44583259  0.13010665  0.25409226 -0.60025515  0.44629166\n",
      "  -1.7833047   0.45234188]\n",
      " [-0.14128254  0.35456689  0.01656988  0.6706945  -2.16778151 -0.40914444\n",
      "  -0.06074329  0.83633669]\n",
      " [-1.20623507  0.34574588  1.23796675  1.66042951 -1.32098073  0.02809306\n",
      "   1.44312277 -0.5836797 ]]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.47643752, -9.05191581, -0.78564606,  2.79359396],\n",
       "       [-0.15109925,  2.9202144 , -1.27887269, -0.71246065],\n",
       "       [-0.9425738 ,  5.93826561,  0.8150957 ,  0.13930859],\n",
       "       [ 1.78432952, -1.04850156,  1.15897674, -1.96445615]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.matmul(q, k.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9771498803132472, 0.8885096187493557, 9.333503460424996)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.var(), k.var(), np.matmul(q, k.T).var()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9771498803132472, 0.8885096187493557, 1.1666879325531243)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "q.var(), k.var(), scaled.var()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52199949, -3.20033552, -0.27776783,  0.98768462],\n",
       "       [-0.05342165,  1.0324517 , -0.45214978, -0.25189288],\n",
       "       [-0.33325016,  2.09949394,  0.28817985,  0.04925302],\n",
       "       [ 0.63085575, -0.37070128,  0.40976016, -0.69454013]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MASKING\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">This is to ensure words don't get context from words generated in the future.\n",
    "\n",
    ">Not required in the encoders, but required int he decoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 0., 0., 0.],\n",
       "       [1., 1., 0., 0.],\n",
       "       [1., 1., 1., 0.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask = np.tril(np.ones( (L, L) ))\n",
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mask[mask == 0] = -np.infty\n",
    "mask[mask == 1] = 0\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0., -inf, -inf, -inf],\n",
       "       [  0.,   0., -inf, -inf],\n",
       "       [  0.,   0.,   0., -inf],\n",
       "       [  0.,   0.,   0.,   0.]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.52199949,        -inf,        -inf,        -inf],\n",
       "       [-0.05342165,  1.0324517 ,        -inf,        -inf],\n",
       "       [-0.33325016,  2.09949394,  0.28817985,        -inf],\n",
       "       [ 0.63085575, -0.37070128,  0.40976016, -0.69454013]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaled + mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = softmax(scaled + mask)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.        , 0.        , 0.        ],\n",
       "       [0.25239615, 0.74760385, 0.        , 0.        ],\n",
       "       [0.07016715, 0.79921051, 0.13062234, 0.        ],\n",
       "       [0.41073752, 0.1508668 , 0.32926364, 0.10913204]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47000748,  1.67941975, -0.58124951,  0.24262047, -0.96695464,\n",
       "        -0.63551672,  1.1676836 ,  1.84772634],\n",
       "       [ 0.43680757,  0.09057291, -0.0494369 ,  0.25119683, -0.69280869,\n",
       "         0.17324739, -1.03848662,  0.80453154],\n",
       "       [ 0.35466767, -0.19215964,  0.06536238,  0.30770488, -0.83073937,\n",
       "         0.25864518, -1.35123725,  0.60041033],\n",
       "       [ 0.07910038,  0.7770173 , -0.07855452,  0.54002878, -1.34565608,\n",
       "        -0.3253505 ,  0.34806036,  1.03885102]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_v = np.matmul(attention, v)\n",
    "new_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.47000748,  1.67941975, -0.58124951,  0.24262047, -0.96695464,\n",
       "        -0.63551672,  1.1676836 ,  1.84772634],\n",
       "       [ 0.42559906, -0.44583259,  0.13010665,  0.25409226, -0.60025515,\n",
       "         0.44629166, -1.7833047 ,  0.45234188],\n",
       "       [-0.14128254,  0.35456689,  0.01656988,  0.6706945 , -2.16778151,\n",
       "        -0.40914444, -0.06074329,  0.83633669],\n",
       "       [-1.20623507,  0.34574588,  1.23796675,  1.66042951, -1.32098073,\n",
       "         0.02809306,  1.44312277, -0.5836797 ]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "v\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax(x):\n",
    "  return (np.exp(x).T / np.sum(np.exp(x), axis=-1)).T\n",
    "\n",
    "def scaled_dot_product_attention(q, k, v, mask=None):\n",
    "  d_k = q.shape[-1]\n",
    "  scaled = np.matmul(q, k.T) / math.sqrt(d_k)\n",
    "  if mask is not None:\n",
    "    scaled = scaled + mask\n",
    "  attention = softmax(scaled)\n",
    "  out = np.matmul(attention, v)\n",
    "  return out, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q\n",
      " [[ 0.1338676  -1.31787852 -0.81580438  0.10849314 -1.86438204 -2.29125958\n",
      "   0.20237417  1.22667764]\n",
      " [-0.12566382 -0.85288647  0.31339589 -0.76331267 -0.05254395  0.17963946\n",
      "  -1.25004825  0.33494957]\n",
      " [ 0.05911044  0.07593472  0.63216622 -0.223841    0.93323609 -1.2360208\n",
      "  -2.64525418  0.48687464]\n",
      " [ 0.59815955 -0.27984435 -0.91039285 -0.19008769  0.63416699  1.99340053\n",
      "   0.90365102 -0.10097996]]\n",
      "K\n",
      " [[ 0.77327056  0.0451663   0.6615367  -0.26743661  0.49088125  0.54616399\n",
      "   0.63656231  0.88535059]\n",
      " [ 0.28640497  0.38361717  2.421019   -0.04920616  0.73570624  1.25312975\n",
      "  -2.25649879 -1.55276228]\n",
      " [ 0.12004555  0.77612413 -0.90071078 -0.11322133  1.60818544 -0.44628416\n",
      "   0.49328192  1.12050032]\n",
      " [-1.48390683  0.30182879 -0.26292456 -0.30120886  0.46111164 -1.08276636\n",
      "   0.76887877  1.16688117]]\n",
      "V\n",
      " [[ 0.47000748  1.67941975 -0.58124951  0.24262047 -0.96695464 -0.63551672\n",
      "   1.1676836   1.84772634]\n",
      " [ 0.42559906 -0.44583259  0.13010665  0.25409226 -0.60025515  0.44629166\n",
      "  -1.7833047   0.45234188]\n",
      " [-0.14128254  0.35456689  0.01656988  0.6706945  -2.16778151 -0.40914444\n",
      "  -0.06074329  0.83633669]\n",
      " [-1.20623507  0.34574588  1.23796675  1.66042951 -1.32098073  0.02809306\n",
      "   1.44312277 -0.5836797 ]]\n",
      "New V\n",
      " [[ 0.47000748  1.67941975 -0.58124951  0.24262047 -0.96695464 -0.63551672\n",
      "   1.1676836   1.84772634]\n",
      " [ 0.43680757  0.09057291 -0.0494369   0.25119683 -0.69280869  0.17324739\n",
      "  -1.03848662  0.80453154]\n",
      " [ 0.35466767 -0.19215964  0.06536238  0.30770488 -0.83073937  0.25864518\n",
      "  -1.35123725  0.60041033]\n",
      " [ 0.07910038  0.7770173  -0.07855452  0.54002878 -1.34565608 -0.3253505\n",
      "   0.34806036  1.03885102]]\n",
      "Attention\n",
      " [[1.         0.         0.         0.        ]\n",
      " [0.25239615 0.74760385 0.         0.        ]\n",
      " [0.07016715 0.79921051 0.13062234 0.        ]\n",
      " [0.41073752 0.1508668  0.32926364 0.10913204]]\n"
     ]
    }
   ],
   "source": [
    "values, attention = scaled_dot_product_attention(q, k, v, mask=mask)\n",
    "print(\"Q\\n\", q)\n",
    "print(\"K\\n\", k)\n",
    "print(\"V\\n\", v)\n",
    "print(\"New V\\n\", values)\n",
    "print(\"Attention\\n\", attention)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
