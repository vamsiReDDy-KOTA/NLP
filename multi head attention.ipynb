{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_length = 4\n",
    "batch_size = 1\n",
    "input_dim = 512\n",
    "d_model = 512\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.4623, -0.1224,  0.4430,  ...,  1.0230,  0.6502,  1.8083],\n",
       "         [ 0.1987,  0.6686, -2.0054,  ..., -0.9855, -1.1529,  0.7186],\n",
       "         [ 0.3960, -0.4231,  0.2926,  ..., -0.4850, -0.9347, -0.9549],\n",
       "         [-1.0724, -0.5286,  0.9893,  ..., -0.8820, -0.0426,  0.9307]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv_layer = nn.Linear(input_dim , 3 * d_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "qkv = qkv_layer(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 1536])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Collecting matplotlib\n",
      "  Downloading matplotlib-3.8.4-cp312-cp312-win_amd64.whl.metadata (5.9 kB)\n",
      "Collecting contourpy>=1.0.1 (from matplotlib)\n",
      "  Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl.metadata (5.8 kB)\n",
      "Collecting cycler>=0.10 (from matplotlib)\n",
      "  Downloading cycler-0.12.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Collecting fonttools>=4.22.0 (from matplotlib)\n",
      "  Downloading fonttools-4.51.0-cp312-cp312-win_amd64.whl.metadata (162 kB)\n",
      "     ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/162.8 kB ? eta -:--:--\n",
      "     -- ------------------------------------- 10.2/162.8 kB ? eta -:--:--\n",
      "     ------ ------------------------------ 30.7/162.8 kB 325.1 kB/s eta 0:00:01\n",
      "     --------- --------------------------- 41.0/162.8 kB 326.8 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------ ------------------ 81.9/162.8 kB 508.4 kB/s eta 0:00:01\n",
      "     ------------------------------- ---- 143.4/162.8 kB 258.0 kB/s eta 0:00:01\n",
      "     --------------------------------- -- 153.6/162.8 kB 247.6 kB/s eta 0:00:01\n",
      "     ------------------------------------ 162.8/162.8 kB 237.9 kB/s eta 0:00:00\n",
      "Collecting kiwisolver>=1.3.1 (from matplotlib)\n",
      "  Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl.metadata (6.5 kB)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\kotaa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (1.26.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\kotaa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (24.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\kotaa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (10.2.0)\n",
      "Collecting pyparsing>=2.3.1 (from matplotlib)\n",
      "  Downloading pyparsing-3.1.2-py3-none-any.whl.metadata (5.1 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\kotaa\\appdata\\roaming\\python\\python312\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\kotaa\\appdata\\roaming\\python\\python312\\site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Downloading matplotlib-3.8.4-cp312-cp312-win_amd64.whl (7.7 MB)\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/7.7 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.1/7.7 MB 871.5 kB/s eta 0:00:09\n",
      "    --------------------------------------- 0.1/7.7 MB 853.3 kB/s eta 0:00:09\n",
      "   - -------------------------------------- 0.2/7.7 MB 1.0 MB/s eta 0:00:08\n",
      "   - -------------------------------------- 0.3/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   - -------------------------------------- 0.4/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.4/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.5/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   -- ------------------------------------- 0.6/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.7/7.7 MB 1.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.7/7.7 MB 1.2 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.7/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   --- ------------------------------------ 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.1 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ---- ----------------------------------- 0.8/7.7 MB 1.0 MB/s eta 0:00:07\n",
      "   ----- ---------------------------------- 1.0/7.7 MB 798.0 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.0/7.7 MB 798.0 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.1/7.7 MB 811.7 kB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 1.1/7.7 MB 798.7 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.2/7.7 MB 806.5 kB/s eta 0:00:09\n",
      "   ------ --------------------------------- 1.3/7.7 MB 864.4 kB/s eta 0:00:08\n",
      "   ------- -------------------------------- 1.4/7.7 MB 909.6 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.4/7.7 MB 902.0 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.5/7.7 MB 913.7 kB/s eta 0:00:07\n",
      "   ------- -------------------------------- 1.5/7.7 MB 892.3 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.5/7.7 MB 885.8 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.5/7.7 MB 885.8 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.6/7.7 MB 875.9 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.6/7.7 MB 875.9 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.6/7.7 MB 875.9 kB/s eta 0:00:07\n",
      "   -------- ------------------------------- 1.6/7.7 MB 875.9 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.7/7.7 MB 852.1 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.9/7.7 MB 878.8 kB/s eta 0:00:07\n",
      "   --------- ------------------------------ 1.9/7.7 MB 880.4 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.0/7.7 MB 899.0 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.0/7.7 MB 881.6 kB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 2.1/7.7 MB 899.1 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.2/7.7 MB 912.6 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.2/7.7 MB 916.9 kB/s eta 0:00:06\n",
      "   ----------- ---------------------------- 2.2/7.7 MB 900.0 kB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 2.3/7.7 MB 897.0 kB/s eta 0:00:07\n",
      "   ------------ --------------------------- 2.3/7.7 MB 899.3 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.3/7.7 MB 896.1 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.4/7.7 MB 886.7 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.4/7.7 MB 877.5 kB/s eta 0:00:06\n",
      "   ------------ --------------------------- 2.4/7.7 MB 876.3 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.5/7.7 MB 879.9 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.5/7.7 MB 879.9 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.5/7.7 MB 879.9 kB/s eta 0:00:06\n",
      "   ------------- -------------------------- 2.5/7.7 MB 844.2 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 2.5/7.7 MB 844.2 kB/s eta 0:00:07\n",
      "   ------------- -------------------------- 2.7/7.7 MB 849.8 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.8/7.7 MB 883.8 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.8/7.7 MB 882.4 kB/s eta 0:00:06\n",
      "   -------------- ------------------------- 2.9/7.7 MB 875.9 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.9/7.7 MB 877.0 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 2.9/7.7 MB 875.8 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.0/7.7 MB 882.0 kB/s eta 0:00:06\n",
      "   --------------- ------------------------ 3.1/7.7 MB 891.7 kB/s eta 0:00:06\n",
      "   ---------------- ----------------------- 3.2/7.7 MB 903.1 kB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 3.2/7.7 MB 897.8 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.3/7.7 MB 906.0 kB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 3.3/7.7 MB 906.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.7 MB 910.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.7 MB 910.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.7 MB 910.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.7 MB 910.0 kB/s eta 0:00:05\n",
      "   ------------------ --------------------- 3.5/7.7 MB 872.0 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.6/7.7 MB 905.4 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.7/7.7 MB 910.1 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.7/7.7 MB 910.4 kB/s eta 0:00:05\n",
      "   ------------------- -------------------- 3.8/7.7 MB 913.1 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 3.9/7.7 MB 922.3 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 3.9/7.7 MB 923.9 kB/s eta 0:00:05\n",
      "   -------------------- ------------------- 4.0/7.7 MB 921.4 kB/s eta 0:00:04\n",
      "   -------------------- ------------------- 4.0/7.7 MB 921.4 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.1/7.7 MB 925.0 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.1/7.7 MB 918.0 kB/s eta 0:00:04\n",
      "   --------------------- ------------------ 4.2/7.7 MB 920.8 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.3/7.7 MB 928.3 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.3/7.7 MB 925.5 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.3/7.7 MB 922.7 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.4/7.7 MB 924.4 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.4/7.7 MB 924.4 kB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 4.4/7.7 MB 915.8 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.4/7.7 MB 914.1 kB/s eta 0:00:04\n",
      "   ----------------------- ---------------- 4.5/7.7 MB 863.3 kB/s eta 0:00:04\n",
      "   ------------------------ --------------- 4.8/7.7 MB 906.3 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 4.8/7.7 MB 906.0 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 4.9/7.7 MB 903.0 kB/s eta 0:00:04\n",
      "   ------------------------- -------------- 4.9/7.7 MB 910.3 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.1/7.7 MB 923.1 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.1/7.7 MB 921.0 kB/s eta 0:00:03\n",
      "   -------------------------- ------------- 5.2/7.7 MB 924.2 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.2/7.7 MB 926.2 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.3/7.7 MB 927.3 kB/s eta 0:00:03\n",
      "   --------------------------- ------------ 5.3/7.7 MB 930.1 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.4/7.7 MB 938.8 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.5/7.7 MB 942.7 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.5/7.7 MB 942.7 kB/s eta 0:00:03\n",
      "   ---------------------------- ----------- 5.6/7.7 MB 933.1 kB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 5.7/7.7 MB 940.9 kB/s eta 0:00:03\n",
      "   ------------------------------ --------- 5.8/7.7 MB 943.7 kB/s eta 0:00:02\n",
      "   ------------------------------ --------- 5.8/7.7 MB 950.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.0/7.7 MB 959.9 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.0/7.7 MB 962.6 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.1/7.7 MB 958.8 kB/s eta 0:00:02\n",
      "   ------------------------------- -------- 6.1/7.7 MB 959.6 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.2/7.7 MB 966.3 kB/s eta 0:00:02\n",
      "   -------------------------------- ------- 6.2/7.7 MB 968.8 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.3/7.7 MB 973.6 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.4/7.7 MB 972.2 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.4/7.7 MB 973.0 kB/s eta 0:00:02\n",
      "   --------------------------------- ------ 6.5/7.7 MB 973.8 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.5/7.7 MB 974.7 kB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 6.7/7.7 MB 982.4 kB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 6.8/7.7 MB 990.6 kB/s eta 0:00:01\n",
      "   ------------------------------------ --- 6.9/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 7.0/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 7.2/7.7 MB 996.6 kB/s eta 0:00:01\n",
      "   -------------------------------------- - 7.5/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.6/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  7.7/7.7 MB 1.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 7.7/7.7 MB 1.0 MB/s eta 0:00:00\n",
      "Downloading contourpy-1.2.1-cp312-cp312-win_amd64.whl (189 kB)\n",
      "   ---------------------------------------- 0.0/189.9 kB ? eta -:--:--\n",
      "   ---------------------------------- ----- 163.8/189.9 kB 5.0 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 163.8/189.9 kB 5.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 184.3/189.9 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 189.9/189.9 kB 1.2 MB/s eta 0:00:00\n",
      "Downloading cycler-0.12.1-py3-none-any.whl (8.3 kB)\n",
      "Downloading fonttools-4.51.0-cp312-cp312-win_amd64.whl (2.2 MB)\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/2.2 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.0/2.2 MB 186.2 kB/s eta 0:00:12\n",
      "   - -------------------------------------- 0.1/2.2 MB 297.7 kB/s eta 0:00:08\n",
      "   ---- ----------------------------------- 0.3/2.2 MB 983.0 kB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.7 MB/s eta 0:00:02\n",
      "   --------- ------------------------------ 0.5/2.2 MB 1.7 MB/s eta 0:00:02\n",
      "   -------------- ------------------------- 0.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   --------------- ------------------------ 0.8/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------- -------------------- 1.0/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------- ------------------- 1.1/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ------------------------ --------------- 1.3/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.4/2.2 MB 2.0 MB/s eta 0:00:01\n",
      "   ----------------------------- ---------- 1.6/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 1.8/2.2 MB 2.1 MB/s eta 0:00:01\n",
      "   ----------------------------------- ---- 2.0/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 2.0/2.2 MB 2.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.2/2.2 MB 2.1 MB/s eta 0:00:00\n",
      "Downloading kiwisolver-1.4.5-cp312-cp312-win_amd64.whl (56 kB)\n",
      "   ---------------------------------------- 0.0/56.0 kB ? eta -:--:--\n",
      "   ---------------------------------------- 56.0/56.0 kB 2.9 MB/s eta 0:00:00\n",
      "Downloading pyparsing-3.1.2-py3-none-any.whl (103 kB)\n",
      "   ---------------------------------------- 0.0/103.2 kB ? eta -:--:--\n",
      "   ---------------------------------------  102.4/103.2 kB 5.8 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 103.2/103.2 kB 2.0 MB/s eta 0:00:00\n",
      "Installing collected packages: pyparsing, kiwisolver, fonttools, cycler, contourpy, matplotlib\n",
      "Successfully installed contourpy-1.2.1 cycler-0.12.1 fonttools-4.51.0 kiwisolver-1.4.5 matplotlib-3.8.4 pyparsing-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'qkv distribution')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "y_val = torch.histc(qkv, bins=200, min=-3, max=3)\n",
    "x_val = np.arange(-1, 1, 0.01) * 3\n",
    "plt.bar(x_val, y_val, align='center', color=['forestgreen'])\n",
    "plt.title('qkv distribution')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_heads = 8\n",
    "head_dim = d_model // num_heads\n",
    "qkv = qkv.reshape(batch_size, sequence_length, num_heads, 3 * head_dim)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 8, 192])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[ 0.4121,  1.0475,  0.9304,  ..., -0.2538,  0.4027, -0.5631],\n",
       "          [ 0.1265,  0.2357, -0.6932,  ..., -0.0689,  0.3813,  0.8424],\n",
       "          [-1.7587, -0.1289, -0.3468,  ..., -0.3009, -0.9601,  0.0314],\n",
       "          ...,\n",
       "          [ 0.9932,  0.2403,  0.8258,  ..., -0.3528,  0.3935, -0.2210],\n",
       "          [-0.6290, -0.6340, -0.5650,  ..., -0.5164, -0.0684, -0.6534],\n",
       "          [ 0.1553,  0.0196, -0.0320,  ...,  1.3388, -0.1815,  0.1959]],\n",
       "\n",
       "         [[-0.7871, -1.2775, -0.5500,  ...,  0.3808, -0.5871,  0.7528],\n",
       "          [ 0.1638,  0.2858,  0.4558,  ...,  0.0402,  0.5766,  0.4770],\n",
       "          [ 0.4846,  0.4001, -0.0595,  ...,  1.1417,  0.7986, -0.1329],\n",
       "          ...,\n",
       "          [-0.1952, -0.2761,  0.4180,  ...,  0.7767, -0.3199, -0.6048],\n",
       "          [ 0.1219, -0.0248,  0.3388,  ...,  0.5961,  0.5987,  0.4035],\n",
       "          [-0.1016,  0.3181,  1.0048,  ...,  0.1074,  0.6160, -1.4779]],\n",
       "\n",
       "         [[-0.2909,  0.1563,  0.2988,  ...,  0.5652, -0.4903,  0.4187],\n",
       "          [-0.0278, -0.9482, -0.7959,  ..., -0.1749,  0.9865,  0.0726],\n",
       "          [ 0.5971,  0.3659, -1.0637,  ..., -0.4715,  0.4194, -0.2575],\n",
       "          ...,\n",
       "          [-0.1587, -1.0009,  0.5166,  ..., -0.4979,  0.2112,  0.3787],\n",
       "          [-0.4595, -0.2248,  0.0903,  ...,  0.8435,  0.3658,  0.7916],\n",
       "          [-0.1316,  0.5220, -0.4718,  ..., -0.7369,  0.2135, -0.0020]],\n",
       "\n",
       "         [[-1.5456,  0.2769,  0.1983,  ..., -0.0109, -0.3120, -1.2084],\n",
       "          [ 0.3731, -0.4286, -0.8065,  ..., -0.1452,  0.4246,  0.1721],\n",
       "          [ 0.1542, -0.6584, -0.7586,  ..., -0.6855,  0.6340, -0.4199],\n",
       "          ...,\n",
       "          [ 0.0982, -0.8818, -0.8240,  ..., -0.5136, -0.2109, -0.2737],\n",
       "          [-0.3694,  0.7943, -0.3870,  ..., -0.5323, -0.0745,  0.9674],\n",
       "          [-0.0884,  0.2546, -1.1889,  ...,  0.5156, -0.3571, -0.7285]]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qkv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 192])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "qkv = qkv.permute(0, 2, 1, 3) # [batch_size, num_heads, sequence_length, 3*head_dim]\n",
    "qkv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]),\n",
       " torch.Size([1, 8, 4, 64]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q, k, v = qkv.chunk(3,dim= -1)\n",
    "q.shape, k.shape, v.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "d_k = q.size()[-1]\n",
    "scaled = torch.matmul(q, k.transpose(-2, -1)) / math.sqrt(d_k)\n",
    "scaled.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kotaa\\AppData\\Local\\Temp\\ipykernel_5636\\3724124494.py:1: UserWarning: The use of `x.T` on tensors of dimension other than 2 to reverse their shape is deprecated and it will throw an error in a future release. Consider `x.mT` to transpose batches of matrices or `x.permute(*torch.arange(x.ndim - 1, -1, -1))` to reverse the dimensions of a tensor. (Triggered internally at ..\\aten\\src\\ATen\\native\\TensorShape.cpp:3641.)\n",
      "  k.T.shape\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 4, 8, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.T.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0847, -1.0901],\n",
       "        [ 0.0769,  1.8695],\n",
       "        [-0.3478, -0.3110]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "y = torch.randn(2, 3)\n",
    "torch.transpose(y, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.0847, -1.0901],\n",
       "        [ 0.0769,  1.8695],\n",
       "        [-0.3478, -0.3110]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.transpose(y, 1, 0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]],\n",
       "\n",
       "         [[True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          ...,\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True],\n",
       "          [True, True, True, True]]]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2) == k.transpose(-2, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 64, 4])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k.transpose(-1, -2).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., -inf, -inf, -inf],\n",
       "        [0., 0., -inf, -inf],\n",
       "        [0., 0., 0., -inf],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mask = torch.full(scaled.size() , float('-inf'))\n",
    "mask = torch.triu(mask, diagonal=1)\n",
    "mask[0][1] # mask for input to a single head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1433,    -inf,    -inf,    -inf],\n",
       "        [-0.2223, -0.2117,    -inf,    -inf],\n",
       "        [ 0.1460, -0.1696,  0.4187,    -inf],\n",
       "        [-0.6582, -0.2578,  0.5641,  0.7072]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(scaled + mask)[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaled += mask\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6269606805367254"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(0.5596) / (np.exp(0.5596) + np.exp(0.0404))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention = F.softmax(scaled, dim=-1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4973, 0.5027, 0.0000, 0.0000],\n",
       "        [0.3286, 0.2397, 0.4317, 0.0000],\n",
       "        [0.1020, 0.1522, 0.3463, 0.3995]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = torch.matmul(attention, v)\n",
    "values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "values, attention = scaled_dot_product(q, k, v, mask=mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 4])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.0000, 0.0000, 0.0000, 0.0000],\n",
       "        [0.4973, 0.5027, 0.0000, 0.0000],\n",
       "        [0.3286, 0.2397, 0.4317, 0.0000],\n",
       "        [0.1020, 0.1522, 0.3463, 0.3995]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 8, 4, 64])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values.size()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "values = values.reshape(batch_size, sequence_length, num_heads * head_dim)\n",
    "values.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_layer = nn.Linear(d_model, d_model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "out = linear_layer(values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 4, 512])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1676,  0.0361, -0.1637,  ..., -0.5512,  0.1939, -0.1296],\n",
       "         [ 0.4908, -0.3093, -0.2582,  ...,  0.5500, -0.1298,  0.1635],\n",
       "         [ 0.6074, -0.2322, -0.0047,  ..., -0.0936,  0.2092, -0.0075],\n",
       "         [-0.0271, -0.1051, -0.0044,  ..., -0.0617, -0.2960, -0.2976]]],\n",
       "       grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import math\n",
    "\n",
    "def scaled_dot_product(q, k, v, mask=None):\n",
    "    d_k = q.size()[-1]\n",
    "    scaled = torch.matmul(q, k.transpose(-1, -2)) / math.sqrt(d_k)\n",
    "    if mask is not None:\n",
    "        scaled += mask\n",
    "    attention = F.softmax(scaled, dim=-1)\n",
    "    values = torch.matmul(attention, v)\n",
    "    return values, attention\n",
    "\n",
    "class MultiheadAttention(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, d_model, num_heads):\n",
    "        super().__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.d_model = d_model\n",
    "        self.num_heads = num_heads\n",
    "        self.head_dim = d_model // num_heads\n",
    "        self.qkv_layer = nn.Linear(input_dim , 3 * d_model)\n",
    "        self.linear_layer = nn.Linear(d_model, d_model)\n",
    "    \n",
    "    def forward(self, x, mask=None):\n",
    "        batch_size, sequence_length, input_dim = x.size()\n",
    "        print(f\"x.size(): {x.size()}\")\n",
    "        qkv = self.qkv_layer(x)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.reshape(batch_size, sequence_length, self.num_heads, 3 * self.head_dim)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        qkv = qkv.permute(0, 2, 1, 3)\n",
    "        print(f\"qkv.size(): {qkv.size()}\")\n",
    "        q, k, v = qkv.chunk(3, dim=-1)\n",
    "        print(f\"q size: {q.size()}, k size: {k.size()}, v size: {v.size()}, \")\n",
    "        values, attention = scaled_dot_product(q, k, v, mask)\n",
    "        print(f\"values.size(): {values.size()}, attention.size:{ attention.size()} \")\n",
    "        values = values.reshape(batch_size, sequence_length, self.num_heads * self.head_dim)\n",
    "        print(f\"values.size(): {values.size()}\")\n",
    "        out = self.linear_layer(values)\n",
    "        print(f\"out.size(): {out.size()}\")\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x.size(): torch.Size([30, 5, 1024])\n",
      "qkv.size(): torch.Size([30, 5, 1536])\n",
      "qkv.size(): torch.Size([30, 5, 8, 192])\n",
      "qkv.size(): torch.Size([30, 8, 5, 192])\n",
      "q size: torch.Size([30, 8, 5, 64]), k size: torch.Size([30, 8, 5, 64]), v size: torch.Size([30, 8, 5, 64]), \n",
      "values.size(): torch.Size([30, 8, 5, 64]), attention.size:torch.Size([30, 8, 5, 5]) \n",
      "values.size(): torch.Size([30, 5, 512])\n",
      "out.size(): torch.Size([30, 5, 512])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "input_dim = 1024\n",
    "d_model = 512\n",
    "num_heads = 8\n",
    "\n",
    "batch_size = 30\n",
    "sequence_length = 5\n",
    "x = torch.randn( (batch_size, sequence_length, input_dim) )\n",
    "\n",
    "model = MultiheadAttention(input_dim, d_model, num_heads)\n",
    "out = model.forward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
