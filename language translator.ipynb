{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "0669b129",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformer import Transformer # this is the transformer.py file?\n",
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f367b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "english_file = './train.en'\n",
    "telugu_file = './train.te'\n",
    "\n",
    "START_TOKEN = ''\n",
    "PADDING_TOKEN = ''\n",
    "END_TOKEN = ''\n",
    "\n",
    "telugu_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
    "                      '0', '1', '2', '3', '4', '5', '6', '7', '8', '9', ':', '<', '=', '>', '?', 'ˌ',\n",
    "                      '౧', '౨' '౩', '౪', '౫', '౬', '౭', '౮', '౯', '౦',\n",
    "                      'అ', 'ఆ', 'ఇ', 'ఈ', 'ఉ', 'ఊ', 'ఋ', 'ౠ', 'ఎ', 'ఏ', 'ఐ', 'ఒ', 'ఓ', 'ఔ', 'అం', 'అః',\n",
    "                      'క', 'ఖ', 'గ', 'ఘ', 'ఙ',\n",
    "                      'చ', 'ఛ', 'జ', 'ఝ', 'ఞ',\n",
    "                      'ట', 'ఠ', 'డ', 'ఢ', 'ణ',\n",
    "                      'త', 'థ', 'ద', 'ధ', 'న',\n",
    "                      'ప', 'ఫ', 'బ', 'భ', 'మ',\n",
    "                      'య', 'ర', 'ల', 'వ', 'శ',\n",
    "                      'ష', 'స', 'హ', 'ళ', 'క్ష', 'ఱ',\n",
    "                    '  ా','ి','ీ','ు','ూ','ృ',  'ె','ే','్','ొ','ో' ,'ౌ','ం' ,  PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "english_vocabulary = [START_TOKEN, ' ', '!', '\"', '#', '$', '%', '&', \"'\", '(', ')', '*', '+', ',', '-', '.', '/',\n",
    "                        '0', '1', '2', '3', '4', '5', '6', '7', '8', '9',\n",
    "                        ':', '<', '=', '>', '?', '@',\n",
    "                        '[', ']', '^', '_', '`',  '/',\n",
    "                        'a', 'b', 'c', 'd', 'e', 'f', 'g', 'h', 'i', 'j', 'k', 'l',\n",
    "                        'm', 'n', 'o', 'p', 'q', 'r', 's', 't', 'u', 'v', 'w', 'x',\n",
    "                        'y', 'z',\n",
    "                        '{', '|', '}', '~', PADDING_TOKEN, END_TOKEN]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2a941fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "index_to_telugu = {k:v for k,v in enumerate(telugu_vocabulary)}\n",
    "telugu_to_index = {v:k for k,v in enumerate(telugu_vocabulary)}\n",
    "index_to_english = {k:v for k,v in enumerate(english_vocabulary)}\n",
    "english_to_index = {v:k for k,v in enumerate(english_vocabulary)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6bab8c61",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(english_file, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    english_sentences = file.readlines()\n",
    "with open(telugu_file, 'r', encoding='utf-8', errors='ignore') as file:\n",
    "    telugu_sentences = file.readlines()\n",
    "\n",
    "# Limit Number of sentences\n",
    "TOTAL_SENTENCES = 200000\n",
    "english_sentences = english_sentences[:TOTAL_SENTENCES]\n",
    "telugu_sentences = telugu_sentences[:TOTAL_SENTENCES]\n",
    "english_sentences = [sentence.rstrip('\\n').lower() for sentence in english_sentences]\n",
    "telugu_sentences = [sentence.rstrip('\\n') for sentence in telugu_sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c0004492",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['have you heard about foie gras?',\n",
       " 'i never thought of acting in films.',\n",
       " 'installed software',\n",
       " 'a case has been registered under sections 302 and 376, ipc.',\n",
       " 'of this, 10 people succumbed to the injuries.',\n",
       " 'her acting has been praised by critics.',\n",
       " 'the bibles viewpoint on this is clearly indicated at colossians 3: 9: do not be lying to one another.',\n",
       " 'the incident was recorded in the cctv footage.',\n",
       " 'respect privacy',\n",
       " '5 lakh would be provided.']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_sentences[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "c730a4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['ఇక ఫ్రూట్ ఫ్లైస్ గురించి మీరు విన్నారా?',\n",
       " 'సూర్య సినిమాల్లో నటించాలని ఎప్పుడూ అనుకోలేదు.',\n",
       " 'స్థాపించబడిన సాఫ్ట్\\u200dవేర్',\n",
       " 'నిందితులపై సెక్షన్ 376 మరియు 302ల కింద కేసు నమోదు చేశాం.',\n",
       " 'అందులో 10 మంది తీవ్రంగా గాయపడ్డారు.',\n",
       " 'నటనకు గాను విమర్శకుల నుంచి ప్రశంసలు పొందింది.',\n",
       " 'ఈ విషయంపై బైబిలు దృక్కోణం కొలొస్సయులు 3 :\\u2060 9లో “ఒకనితో ఒకడు అబద్ధమాడకుడి ” అని స్పష్టంగా సూచించబడింది.',\n",
       " 'ఈ ప్రమాద దృశ్యాలు సీసీటీవీ ఫుటేజ్\\u200cలో రికార్డ్ అయ్యాయి.',\n",
       " 'గోప్యత పాటించండి',\n",
       " '5లక్షలు సాయం అందజేశారు.']"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telugu_sentences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "23bfed9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "97th percentile length telugu: 169.0\n",
      "97th percentile length English: 178.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "PERCENTILE = 97\n",
    "print( f\"{PERCENTILE}th percentile length telugu: {np.percentile([len(x) for x in telugu_sentences], PERCENTILE)}\" )\n",
    "print( f\"{PERCENTILE}th percentile length English: {np.percentile([len(x) for x in english_sentences], PERCENTILE)}\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "1daf75a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of sentences: 200000\n",
      "Number of valid sentences: 16103\n"
     ]
    }
   ],
   "source": [
    "max_sequence_length = 200\n",
    "\n",
    "def is_valid_tokens(sentence, vocab):\n",
    "    for token in list(set(sentence)):\n",
    "        if token not in vocab:\n",
    "            return False\n",
    "    return True\n",
    "\n",
    "def is_valid_length(sentence, max_sequence_length):\n",
    "    return len(list(sentence)) < (max_sequence_length - 1) # need to re-add the end token so leaving 1 space\n",
    "\n",
    "valid_sentence_indicies = []\n",
    "for index in range(len(telugu_sentences)):\n",
    "    telugu_sentence, english_sentence = telugu_sentences[index], english_sentences[index]\n",
    "    if is_valid_length(telugu_sentence, max_sequence_length) \\\n",
    "      and is_valid_length(english_sentence, max_sequence_length) \\\n",
    "      and is_valid_tokens(telugu_sentence, telugu_vocabulary):\n",
    "        valid_sentence_indicies.append(index)\n",
    "\n",
    "print(f\"Number of sentences: {len(telugu_sentences)}\")\n",
    "print(f\"Number of valid sentences: {len(valid_sentence_indicies)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8050d4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "telugu_sentences = [telugu_sentences[i] for i in valid_sentence_indicies]\n",
    "english_sentences = [english_sentences[i] for i in valid_sentence_indicies]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f1bdabe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['\"\"\"సూపర్ బౌల్.\"', 'ఏ పనిచేయలేరు.', '02 లక్షల వరకు తగ్గించింది.']"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "telugu_sentences[:3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "8aead8b7",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "SentenceEmbedding.__init__() takes 3 positional arguments but 7 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m max_sequence_length \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m200\u001b[39m\n\u001b[0;32m     10\u001b[0m kn_vocab_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(telugu_vocabulary)\n\u001b[1;32m---> 12\u001b[0m transformer \u001b[38;5;241m=\u001b[39m \u001b[43mTransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mffn_hidden\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mdrop_prob\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mkn_vocab_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                          \u001b[49m\u001b[43menglish_to_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mtelugu_to_index\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mSTART_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mEND_TOKEN\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     23\u001b[0m \u001b[43m                          \u001b[49m\u001b[43mPADDING_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kotaa\\nlp\\transformer.py:289\u001b[0m, in \u001b[0;36mTransformer.__init__\u001b[1;34m(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kn_vocab_size, english_to_index, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\u001b[0m\n\u001b[0;32m    275\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m    276\u001b[0m              d_model, \n\u001b[0;32m    277\u001b[0m              ffn_hidden, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    286\u001b[0m              END_TOKEN, \n\u001b[0;32m    287\u001b[0m              PADDING_TOKEN):\n\u001b[0;32m    288\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 289\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder \u001b[38;5;241m=\u001b[39m \u001b[43mEncoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mffn_hidden\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_heads\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdrop_prob\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_layers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menglish_to_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    290\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder \u001b[38;5;241m=\u001b[39m Decoder(d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, kannada_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\n\u001b[0;32m    291\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mLinear(d_model, kn_vocab_size)\n",
      "File \u001b[1;32mc:\\Users\\kotaa\\nlp\\transformer.py:176\u001b[0m, in \u001b[0;36mEncoder.__init__\u001b[1;34m(self, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN)\u001b[0m\n\u001b[0;32m    174\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, d_model, ffn_hidden, num_heads, drop_prob, num_layers, max_sequence_length, language_to_index, START_TOKEN, END_TOKEN, PADDING_TOKEN):\n\u001b[0;32m    175\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m()\n\u001b[1;32m--> 176\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msentence_embedding \u001b[38;5;241m=\u001b[39m \u001b[43mSentenceEmbedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_sequence_length\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43md_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlanguage_to_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mSTART_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mEND_TOKEN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mPADDING_TOKEN\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    177\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers \u001b[38;5;241m=\u001b[39m SequentialEncoder(\u001b[38;5;241m*\u001b[39m[EncoderLayer(d_model, ffn_hidden, num_heads, drop_prob) \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(num_layers)])\n",
      "\u001b[1;31mTypeError\u001b[0m: SentenceEmbedding.__init__() takes 3 positional arguments but 7 were given"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "d_model = 512\n",
    "batch_size = 30\n",
    "ffn_hidden = 2048\n",
    "num_heads = 8\n",
    "drop_prob = 0.1\n",
    "num_layers = 1\n",
    "max_sequence_length = 200\n",
    "kn_vocab_size = len(telugu_vocabulary)\n",
    "\n",
    "transformer = Transformer(d_model,\n",
    "                          ffn_hidden,\n",
    "                          num_heads,\n",
    "                          drop_prob,\n",
    "                          num_layers,\n",
    "                          max_sequence_length,\n",
    "                          kn_vocab_size,\n",
    "                          english_to_index,\n",
    "                          telugu_to_index,\n",
    "                          START_TOKEN,\n",
    "                          END_TOKEN,\n",
    "                          PADDING_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "78c95062",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[50], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mtransformer\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "transformer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "04662e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class TextDataset(Dataset):\n",
    "\n",
    "    def __init__(self, english_sentences, telugu_sentences):\n",
    "        self.english_sentences = english_sentences\n",
    "        self.telugu_sentences = telugu_sentences\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.english_sentences)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.english_sentences[idx], self.telugu_sentences[idx]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "21c90b25",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = TextDataset(english_sentences, telugu_sentences)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "af1d26da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16103"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ac5fcec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('it cannot work.', 'ఏ పనిచేయలేరు.')"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "493a5036",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_loader = DataLoader(dataset, batch_size)\n",
    "iterator = iter(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "8066ddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('super bowl.', 'it cannot work.', 'rs 6.02 crore.', 'he is just one...', 'i have never sulked.', 'inability to control urination', 'prices drop', 'it means elder sister.', 'the hair is porous.', 'the girl died in the incident.', 'nuzivedu road', 'why do you need the power?', 'however, police were silent on the matter.', 'we can do this thing.', 'advantage bjp!', 'floods in kerala', 'under this scheme, government earmarked rs.', 'this is a major blow', 'availability & pricing', 'go well', 'yet another couple commit suicide', 'step two: segregation', '49 people dead.', 'what is the matter?', 'category: telugu stage actors', 'come back!', 'smith hit', 'the process', 'whats the venue?', 'its gone.'), ('\"\"\"సూపర్ బౌల్.\"', 'ఏ పనిచేయలేరు.', '02 లక్షల వరకు తగ్గించింది.', 'అతనొక్కడే .', 'నేనెప్పుడూ చీట్ చేయలేదు', 'మూత్రవిసర్జన నియంత్రణ కోల్పోవడం', 'ధరలు తగ్గేవి ఇవే', 'అంటే పెద్దన్నయ్య అని అర్థం.', 'జుట్టు బోలెడంత ఉంది.', 'ఈ ఘటనలో కూతురు చనిపోయింది.', 'నూజివీడు రోడ్డు', 'నీకు శక్తి ఎందుకు అవసరం?', 'అయితే పోలీసులు ఈ ఘటన గురించి పెదవి విప్పడం లేదు.', 'ఆ పని మనం చెయ్యగలం.', 'అసోం బిజెపికే అనుకూలం!', 'కేరళలో వరదల బీభత్సం', 'ఈ పథకం కింద పశువులకు ప్రభుత్వమే రూ.', 'ఇది పెద్ద దెబ్బ', 'ఆఫర్స్ & లభ్యత', 'మంచి నడవడి.', 'మరో ప్రేమ జంట ఆత్మహత్య', 'రెండవ దశ: అసెంబ్లీ', 'ఒక్కరోజే 49 మంది మృతి', 'భువనక్క ఏమనుకుందో ఏమో?', 'వర్గం:తెలుగు రంగస్థల నటులు', 'తిరిగి తిరిగీ తిప్పలే!', 'స్మిత్ డకౌట్', 'ప్రక్రియ.', 'వేదికలు ఏమిటి?', \"' అని వెళ్లిపోయింది.\")]\n",
      "[('with you can:', '180 crore.', 'episode 3: revenge of the sith', 'i dont see it.', 'are managed.', 'its about balance and harmony.', 'she did not turn up.', 'entry to the temple is free of charge', 'let us know the story behind this.', 'height of 20 feet.', 'whos got the money?', 'bawse lady', 'it came out of this.', 'otherwise, nothing much.', 'the kids were shocked!', 'whats theirs?', 'here are a few useful tips:', 'no result.', 'the stay vacation application', '66 crore, he said.', 'water and ration.', 'so what is the deal?', 'do up a wall', 'water conservation', 'why did this incident happen?', 'whats shocking?', 'learn from everyone.', 'everybody knows that!', \"the music director's name has not been announced.\", 'civil suit no.78-a'), ('తో మీరు:', '180 కోట్లు ఖర్చు చేయబోతోంది.', '\"ఎపిసోడ్ 3: సిత్ \"\"యొక్క రివెంజ్\"', 'అని చూడను.', 'నిర్వహణలో ఉంది.', 'ఇది సంతులనం మరియు నిష్పత్తి గురించి.', 'ఆమె వంచిన తల ఎత్తలేదు.', 'టెంపుల్ కు ఎంట్రీ ఫీసు లేదు', 'దీని వెనుక ఉన్న కథ తెలుసుకుంటే.', 'ఎత్తు 20 సెంటీమీటర్లు.', 'నిధులు సేకరించిం దెవరో?', 'బబుష్క లేడీ', 'దీంతో ఈ విషయం బయటకు పొక్కింది.', 'లేదంటే ఏమీ లేదన్నట్లే లెక్క.', 'పిల్లల థ్రిల్డ్ చేయబడుతుంది!', 'వీళ్ళ సంగతి ఏంటో?', 'కొన్ని సూచనలు :', 'నిందించి ఫలితం లేదు.', 'స్టే వెకేషన్ అప్లికేషన్', '66 వేల కోట్లకు చేరిందని .', 'స్పంజిక మరియు నీరు .', 'సో ఒప్పందం ఏమిటి?', 'ఒక గోడ వేయడం', 'జల సంరక్షణ', 'ఆ సంఘటన ఎందుకు జరిగింది?', 'ఆశ్చర్యమేమున్నది?', 'అందరి నుంచీ నేర్చుకోనేది.', 'ఈ సంగతి అందరికీ తెలిసిందే!', 'సంగీత దర్శకుడి పేరు వెల్లడించలేదు.', 'సివిల్ సూట్ నెం .78-ఎ')]\n",
      "[('the puppy followed him.', 'opposition vs bjp', 'this caused tension.', 'the people held strong protest.', 'bribery is a crime.', 'film director puri', 'restructure land acquisition act', 'you cant do anything.', 'where are the ?real?', 'crude prices up', 'discount: rs 50,000', 'come forward.', 'hair colouring', 'what is freedom then?', 'under the rs.', '250 and rs.', 'however, it is true.', \"who's the lovely?\", 'economic crisis -', 'pauls counsel is still applicable.', 'this is the message in the film.', 'winners of various contests', 'best movie.', 'so she told her husband of her wishes, and he willingly cooperated.', 'for treatments.', 'persistence is key.', 'what not to do', 'anirudh is the music director of the film.', 'prices slashed!', 'so is delhi.'), ('బీబమ్మ అతని వెంట నడిచింది.', 'బీజేపీతో విపక్షం పోటీ', 'దీంతో ఉద్రిక్తత చోటుచేసుకుంది.', '్రజల్లో తీవ్ర వ్యతిరేకత వచ్చింది.', 'లంచం అనేది నేరం.', 'పూరి దర్శకుడు.', 'భూ సేకరణ చట్ట సవరణ', 'ఏమీ చేయలేరు.', 'అసలు తనెక్కడుంటుంది?', 'క్రూడ్ ధరలు అప్', 'రూ. 50,000 డిస్కౌంట్', 'ుందుకు రండి.', 'జుట్టు రంగు సెట్ చేయండి', 'ఇప్పుడు స్వతంత్రం అంటే ఏమిటి?', 'పంప ప్రశస్తి కింద రూ.', '250, ఇతరులు రూ.', 'అయితే, ఈ మొగ్గ లో నిజం.', 'లవ్లీ ఎవరు?', 'తీవ్ర సంక్షోభంలో ఆర్ధిక వ్యవస్థ', 'పౌలు ఉపదేశం ఇప్పటికీ వర్తిస్తుంది.', 'అనే సందేశంతో రూపొందిన చిత్రమిది.', 'వివిధ ఈవెంట్లలో విజేతలు', 'ఉత్తమ చిత్రం.', 'ఆమె తన కోరికను తన భర్తకు చెప్పింది.', 'చికిత్స కోసం పరిస్థితులు.', 'నిలకడ ఎప్పటికీ కీలకమే.', 'ఏమి చేయకూడదు', 'అనిరుద్ సంగీత దర్శకుడు.', 'ధరల మీద మన్నుపొయ్య !', 'అదే- ఢిల్లీ.')]\n",
      "[('a new dawn?', 'there are playgrounds and childrens play areas.', 'what is vitiligo?', \"it's me!\", 'that is the downfall.', 'what is the second about?', 'photograph image:', 'reports recommendations', '500 to rs.', 'centre gives rs.', 'clean your hands often.', 'look at this here.', 'her family and friends supported her.', 'heres the videocheck it out', 'they had two kids', 'music: anirudh ravichander', 'solve the problem', 'it seems a tad scary.', 'the matter came to the notice of police.', 'bjp vision document:', 'and why the bjp?', 'what was done', 'fall of wickets: 1-17, 2-29, 3-128, 4-237.', 'a stomach ache.', 'music director: chirantan bhatt', 'it was in english.', 'why the uncertainty?', 'the couple has a six-year-old daughter.', '32,500 on an income of rs.', 'the sport is also 45 kg lighter than the larger range rover'), ('మళ్లీ ఎప్పుడో కొత్త ముహూర్తం?', 'పిల్లలకు ఈత కొలను మరియు ఆట స్థలం ఉంది.', 'బొల్లి అంటే ఏమిటి?', 'నేనూ అంతే!', 'ఇదే అదిపెద్ద పతనం.', 'రెండోది తనకేం?', 'రెసిపీ ఫోటో:', 'నివేదన కోసం సూచనలు', '500ల నుండి రూ.', 'కేంద్రం ఈ మద్య రూ.', 'ేతులను ఎప్పటికప్పుడు శుభ్రం చేసుకోండి.', 'ఇదిగో, ఇక్కడ చూడండి.', 'దీనికి ఆమె కుటుంబం, సహచరుల మద్దతు లభించింది.', 'ఆ వీడియో ఇదిగో . మీరూ చూడండి.', 'వీరికి పిల్లలు లేరు', 'సంగీతం: అనిరుధ్ రవిచందర్', 'సమస్యను పరిష్కరించుకోండి', 'అనుక్షణం భయపడుతున్నట్లు కనిపిస్తుంది.', 'ఈ విషయం పోలీసుల చెవిలో పడింది.', 'బీజేపీ మేనిఫెస్టో:', 'మరి బిజెపికి ఎందుకింత బెదురు?', 'చేసింది ఏంది?', 'వికెట్ల పతనం: 1-17, 2-29, 3-128, 4-237.', 'కడుపునొప్పి ఉంటుంది.', 'సంగీతం : చిరంతన్ భట్', 'అది ఇంగ్లీష్ లో వచ్చింది.', 'అభద్రత ఎందుకు?', 'మనో దంపతులకు ఏడేళ్ల కూతురు ఉంది.', '32,500, ప్రొద్దుటూరులో రూ.', 'రెగ్యులర్ రేంజ్ రోవర్తో పోల్చుకుంటే రేంజ్ రోవర్ స్పోర్ట్ 420 కేజీల తక్కువ బరువును కలిగి ఉంటుంది')]\n",
      "[('nude makeup', 'if you work hard, success is guaranteed.', 'metal sequins', 'design thinking', 'the centre said ...', 'step 3: beatification', '600 crore has been made.', 'post name: office assistant', 'this takes some practice to do that.', 'before the game', 'here no one cared.', 'life has no destination.', 'please dont compare', 'the inter- ministerial committee', 'she died during her treatment.', 'what is, you ask?', '100 notes, one bundle of rs.', 'he had expressed concern over the situation.', 'this is somewhere in london.', 'two petrol and one diesel.', 'the generation that was', 'it is a simple process and does not take much time.', 'he doesnt have a name.', 'second encounter', 'the incident took place in delhi.', 'he was taken to police station.', 'the total value of the contract is rs', 'more than 150.', 'and its not necessary either.', 'what a grandiose idea.'), ('నగ్న మేకప్.', 'కష్టపడితే తప్పకుండ విజయం వస్తుంది.', 'మెటల్ షీల్డ్స్', 'ఆలోచనలకు రూపకల్పన.', 'కేంద్రం చెప్పిందిది', 'దశ 3: విక్షేపం', '600కోట్లు ఖర్చు చేసింది.', 'పోస్టు పేరు: ఆఫీస్ అసిస్టెంట్', 'దీనికోసం ముందే కొంత కసరత్తు చేసుకోవటం అవసరం.', 'టకు ముందు.', 'అక్కడ ఈమెను ఎవరూ పట్టించుకోలేదు.', 'జీవితంలో ఒక గమ్యం అంటూ ఉండదు.', 'దయచేసి పోల్చకండి.', 'ఇంటర్ మినిస్టీరియల్ కమిటీ', 'ఇంతలోనే చికిత్స పొందుతూ ఆమె మృతిచెందింది.', 'ఏమయింది, మీరు అడగండి?', '100 నోట్లను రూ.', 'ఆ పరిస్థితి పట్ల తీవ్ర ఆందోళన ప్రకటించింది.', 'అదీ లండన్ దేశంలో.', 'ఇందులో ఒకటి పెట్రోల్, రెండు డీజిల్.', 'అప్పటి తరం', 'ఇది సులభం, మరియు అది ఎక్కువ సమయం తీసుకోదు.', 'ఆయనకు ఆ పేరు పొందే అర్హత లేదు.', 'రెండవ కలయిక', 'ఈ ఘటన దిల్లీలో జరిగింది.', 'పోలీసు స్టేషన్ వద్ద అతనికి వచ్చింది.', 'ఈ మొత్తం పెట్టుబడుల విలువ రూ', '150కు మించి ఇవ్వటంలేదు.', 'మరియు అవసరం లేదు.', 'ఎంత గొప్ప ఆలోచన.')]\n"
     ]
    }
   ],
   "source": [
    "for batch_num, batch in enumerate(iterator):\n",
    "    print(batch)\n",
    "    if batch_num > 3:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "51858a43",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[57], line 7\u001b[0m\n\u001b[0;32m      3\u001b[0m criterian \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mCrossEntropyLoss(ignore_index\u001b[38;5;241m=\u001b[39mtelugu_to_index[PADDING_TOKEN],\n\u001b[0;32m      4\u001b[0m                                 reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnone\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# When computing the loss, we are ignoring cases when the label is the padding token\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m params \u001b[38;5;129;01min\u001b[39;00m \u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mparameters():\n\u001b[0;32m      8\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m params\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m      9\u001b[0m         nn\u001b[38;5;241m.\u001b[39minit\u001b[38;5;241m.\u001b[39mxavier_uniform_(params)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from torch import nn\n",
    "\n",
    "criterian = nn.CrossEntropyLoss(ignore_index=telugu_to_index[PADDING_TOKEN],\n",
    "                                reduction='none')\n",
    "\n",
    "# When computing the loss, we are ignoring cases when the label is the padding token\n",
    "for params in transformer.parameters():\n",
    "    if params.dim() > 1:\n",
    "        nn.init.xavier_uniform_(params)\n",
    "\n",
    "optim = torch.optim.Adam(transformer.parameters(), lr=1e-4)\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78fcaa0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "NEG_INFTY = -1e9\n",
    "\n",
    "def create_masks(eng_batch, kn_batch):\n",
    "    num_sentences = len(eng_batch)\n",
    "    look_ahead_mask = torch.full([max_sequence_length, max_sequence_length] , True)\n",
    "    look_ahead_mask = torch.triu(look_ahead_mask, diagonal=1)\n",
    "    encoder_padding_mask = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_self_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "    decoder_padding_mask_cross_attention = torch.full([num_sentences, max_sequence_length, max_sequence_length] , False)\n",
    "\n",
    "    for idx in range(num_sentences):\n",
    "      eng_sentence_length, kn_sentence_length = len(eng_batch[idx]), len(kn_batch[idx])\n",
    "      eng_chars_to_padding_mask = np.arange(eng_sentence_length + 1, max_sequence_length)\n",
    "      kn_chars_to_padding_mask = np.arange(kn_sentence_length + 1, max_sequence_length)\n",
    "      encoder_padding_mask[idx, :, eng_chars_to_padding_mask] = True\n",
    "      encoder_padding_mask[idx, eng_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_self_attention[idx, :, kn_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_self_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "      decoder_padding_mask_cross_attention[idx, :, eng_chars_to_padding_mask] = True\n",
    "      decoder_padding_mask_cross_attention[idx, kn_chars_to_padding_mask, :] = True\n",
    "\n",
    "    encoder_self_attention_mask = torch.where(encoder_padding_mask, NEG_INFTY, 0)\n",
    "    decoder_self_attention_mask =  torch.where(look_ahead_mask + decoder_padding_mask_self_attention, NEG_INFTY, 0)\n",
    "    decoder_cross_attention_mask = torch.where(decoder_padding_mask_cross_attention, NEG_INFTY, 0)\n",
    "    return encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "3996ccc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index out of range in self",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[64], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask \u001b[38;5;241m=\u001b[39m create_masks(eng_batch, te_batch)\n\u001b[0;32m     13\u001b[0m optim\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m---> 14\u001b[0m te_predictions \u001b[38;5;241m=\u001b[39m \u001b[43mtransformer\u001b[49m\u001b[43m(\u001b[49m\u001b[43meng_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     15\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mte_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     16\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mencoder_self_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdecoder_self_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     18\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdecoder_cross_attention_mask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m     19\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menc_start_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[43m                             \u001b[49m\u001b[43menc_end_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdec_start_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mdec_end_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m     23\u001b[0m labels \u001b[38;5;241m=\u001b[39m transformer\u001b[38;5;241m.\u001b[39mdecoder\u001b[38;5;241m.\u001b[39msentence_embedding\u001b[38;5;241m.\u001b[39mbatch_tokenize(kn_batch, start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     24\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterian(\n\u001b[0;32m     25\u001b[0m     te_predictions\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, kn_vocab_size)\u001b[38;5;241m.\u001b[39mto(device),\n\u001b[0;32m     26\u001b[0m     labels\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     27\u001b[0m )\u001b[38;5;241m.\u001b[39mto(device)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\nlp\\transformer.py:302\u001b[0m, in \u001b[0;36mTransformer.forward\u001b[1;34m(self, x, y, encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask, enc_start_token, enc_end_token, dec_start_token, dec_end_token)\u001b[0m\n\u001b[0;32m    292\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \n\u001b[0;32m    293\u001b[0m             x, \n\u001b[0;32m    294\u001b[0m             y, \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    300\u001b[0m             dec_start_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;66;03m# We should make this true\u001b[39;00m\n\u001b[0;32m    301\u001b[0m             dec_end_token\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m): \u001b[38;5;66;03m# x, y are batch of sentences\u001b[39;00m\n\u001b[1;32m--> 302\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoder_self_attention_mask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_start_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menc_end_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    303\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecoder(x, y, decoder_self_attention_mask, decoder_cross_attention_mask, start_token\u001b[38;5;241m=\u001b[39mdec_start_token, end_token\u001b[38;5;241m=\u001b[39mdec_end_token)\n\u001b[0;32m    304\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear(out)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\nlp\\transformer.py:179\u001b[0m, in \u001b[0;36mEncoder.forward\u001b[1;34m(self, x, self_attention_mask, start_token, end_token)\u001b[0m\n\u001b[0;32m    178\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, self_attention_mask, start_token, end_token):\n\u001b[1;32m--> 179\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msentence_embedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_token\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend_token\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    180\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlayers(x, self_attention_mask)\n\u001b[0;32m    181\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\nlp\\transformer.py:72\u001b[0m, in \u001b[0;36mSentenceEmbedding.forward\u001b[1;34m(self, x, start_token, end_token)\u001b[0m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, start_token, end_token): \u001b[38;5;66;03m# sentence\u001b[39;00m\n\u001b[0;32m     71\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_tokenize(x, start_token, end_token)\n\u001b[1;32m---> 72\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     73\u001b[0m     pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_encoder()\u001b[38;5;241m.\u001b[39mto(get_device())\n\u001b[0;32m     74\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x \u001b[38;5;241m+\u001b[39m pos)\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\module.py:1130\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1126\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1127\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1128\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1129\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1130\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[0;32m   1131\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[0;32m   1132\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\modules\\sparse.py:158\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    160\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\torch\\nn\\functional.py:2199\u001b[0m, in \u001b[0;36membedding\u001b[1;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[0;32m   2193\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[0;32m   2194\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[0;32m   2195\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[0;32m   2196\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[0;32m   2197\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[0;32m   2198\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[1;32m-> 2199\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mIndexError\u001b[0m: index out of range in self"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "transformer.train()\n",
    "transformer.to(device)\n",
    "total_loss = 0\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        transformer.train()\n",
    "        eng_batch, te_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, te_batch)\n",
    "        optim.zero_grad()\n",
    "        te_predictions = transformer(eng_batch,\n",
    "                                     te_batch,\n",
    "                                     encoder_self_attention_mask.to(device),\n",
    "                                     decoder_self_attention_mask.to(device),\n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(kn_batch, start_token=False, end_token=True)\n",
    "        loss = criterian(\n",
    "            te_predictions.view(-1, kn_vocab_size).to(device),\n",
    "            labels.view(-1).to(device)\n",
    "        ).to(device)\n",
    "        valid_indicies = torch.where(labels.view(-1) == telugu_to_index[PADDING_TOKEN], False, True)\n",
    "        loss = loss.sum() / valid_indicies.sum()\n",
    "        loss.backward()\n",
    "        optim.step()\n",
    "        #train_losses.append(loss.item())\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"Kannada Translation: {te_batch[0]}\")\n",
    "            te_sentence_predicted = torch.argmax(te_predictions[0], axis=1)\n",
    "            predicted_sentence = \"\"\n",
    "            for idx in te_sentence_predicted:\n",
    "              if idx == telugu_to_index[END_TOKEN]:\n",
    "                break\n",
    "              predicted_sentence += index_to_telugu[idx.item()]\n",
    "            print(f\"Kannada Prediction: {predicted_sentence}\")\n",
    "\n",
    "\n",
    "            transformer.eval()\n",
    "            te_sentence = (\"\",)\n",
    "            eng_sentence = (\"should we go to the mall?\",)\n",
    "            for word_counter in range(max_sequence_length):\n",
    "                encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask= create_masks(eng_sentence, te_sentence)\n",
    "                predictions = transformer(eng_sentence,\n",
    "                                          te_sentence,\n",
    "                                          encoder_self_attention_mask.to(device),\n",
    "                                          decoder_self_attention_mask.to(device),\n",
    "                                          decoder_cross_attention_mask.to(device),\n",
    "                                          enc_start_token=False,\n",
    "                                          enc_end_token=False,\n",
    "                                          dec_start_token=True,\n",
    "                                          dec_end_token=False)\n",
    "                next_token_prob_distribution = predictions[0][word_counter] # not actual probs\n",
    "                next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                next_token = index_to_telugu[next_token_index]\n",
    "                te_sentence = (te_sentence[0] + next_token, )\n",
    "                if next_token == END_TOKEN:\n",
    "                  break\n",
    "\n",
    "            print(f\"Evaluation translation (should we go to the mall?) : {te_sentence}\")\n",
    "            print(\"-------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c45ab3d9",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transformer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 8\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Define your transformer model\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Move model to device\u001b[39;00m\n\u001b[0;32m      7\u001b[0m device \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m \u001b[43mtransformer\u001b[49m\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Define optimizer and learning rate\u001b[39;00m\n\u001b[0;32m     11\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m optim\u001b[38;5;241m.\u001b[39mAdam(transformer\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transformer' is not defined"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define your transformer model\n",
    "\n",
    "# Move model to device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "transformer.to(device)\n",
    "\n",
    "# Define optimizer and learning rate\n",
    "optimizer = optim.Adam(transformer.parameters(), lr=0.001)\n",
    "\n",
    "# Assuming `criterion` is your loss function (e.g., CrossEntropyLoss)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Training loop\n",
    "transformer.train()\n",
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch}\")\n",
    "    iterator = iter(train_loader)\n",
    "    \n",
    "    for batch_num, batch in enumerate(iterator):\n",
    "        eng_batch, te_batch = batch\n",
    "        encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_batch, te_batch)\n",
    "        \n",
    "        # Forward pass\n",
    "        optimizer.zero_grad()\n",
    "        te_predictions = transformer(eng_batch,\n",
    "                                     te_batch,\n",
    "                                     encoder_self_attention_mask.to(device),\n",
    "                                     decoder_self_attention_mask.to(device),\n",
    "                                     decoder_cross_attention_mask.to(device),\n",
    "                                     enc_start_token=False,\n",
    "                                     enc_end_token=False,\n",
    "                                     dec_start_token=True,\n",
    "                                     dec_end_token=True)\n",
    "        \n",
    "        # Compute loss\n",
    "        labels = transformer.decoder.sentence_embedding.batch_tokenize(te_batch, start_token=False, end_token=True)\n",
    "        loss = criterion(te_predictions.view(-1, kn_vocab_size).to(device),\n",
    "                         labels.view(-1).to(device))\n",
    "        \n",
    "        # Apply masking to ignore padding tokens\n",
    "        valid_indices = (labels.view(-1) != telugu_to_index[PADDING_TOKEN])\n",
    "        masked_loss = (loss * valid_indices.float()).sum() / valid_indices.sum()\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        masked_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Logging\n",
    "        if batch_num % 100 == 0:\n",
    "            print(f\"Iteration {batch_num} : {masked_loss.item()}\")\n",
    "            print(f\"English: {eng_batch[0]}\")\n",
    "            print(f\"telugu Translation: {te_batch[0]}\")\n",
    "            \n",
    "            # Inference (Evaluation mode)\n",
    "            transformer.eval()\n",
    "            with torch.no_grad():\n",
    "                eng_sentence = (\"should we go to the mall?\",)\n",
    "                te_sentence = (\"\",)\n",
    "                \n",
    "                for word_counter in range(max_sequence_length):\n",
    "                    encoder_self_attention_mask, decoder_self_attention_mask, decoder_cross_attention_mask = create_masks(eng_sentence, te_sentence)\n",
    "                    \n",
    "                    predictions = transformer(eng_sentence,\n",
    "                                              te_sentence,\n",
    "                                              encoder_self_attention_mask.to(device),\n",
    "                                              decoder_self_attention_mask.to(device),\n",
    "                                              decoder_cross_attention_mask.to(device),\n",
    "                                              enc_start_token=False,\n",
    "                                              enc_end_token=False,\n",
    "                                              dec_start_token=True,\n",
    "                                              dec_end_token=False)\n",
    "                    \n",
    "                    next_token_prob_distribution = predictions[0][word_counter]\n",
    "                    next_token_index = torch.argmax(next_token_prob_distribution).item()\n",
    "                    next_token = index_to_telugu[next_token_index]\n",
    "                    te_sentence = (te_sentence[0] + next_token,)\n",
    "                    \n",
    "                    if next_token == END_TOKEN:\n",
    "                        break\n",
    "                \n",
    "                print(f\"Evaluation translation (should we go to the mall?) : {te_sentence}\")\n",
    "                print(\"-------------------------------------------\")\n",
    "                \n",
    "            transformer.train()  # Switch back to training mode\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d416255d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
